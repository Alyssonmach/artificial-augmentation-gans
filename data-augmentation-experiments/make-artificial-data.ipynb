{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Artificial Data with GANS\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Auxiliary Packages\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import generators\n",
    "import warnings\n",
    "import utils\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Model Generation Parameters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 64 \n",
    "mnist_classes, fashion_mnist_classes = 10, 10\n",
    "emnist_letters_classes, celeba_classes = 27, 3\n",
    "gray_shape, color_shape = (1, 28, 28), (3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorSNGANWGANGP_V2_0(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(67, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_input_dim1 = utils.get_input_dimensions(z_dim, mnist_classes)\n",
    "sngan_wgan_gp_mnist = generators.GeneratorSNGANWGANGP_V1_0(z_dim = generator_input_dim1)\n",
    "generator_input_dim2 = utils.get_input_dimensions(z_dim, fashion_mnist_classes)\n",
    "sngan_wgan_gp_fashion_mnist = generators.GeneratorSNGANWGANGP_V1_0(z_dim = generator_input_dim2)\n",
    "generator_input_dim3 = utils.get_input_dimensions(z_dim, emnist_letters_classes)\n",
    "sngan_wgan_gp_emnist_letters = generators.GeneratorSNGANWGANGP_V1_0(z_dim = generator_input_dim3)\n",
    "generator_input_dim4 = utils.get_input_dimensions(z_dim, celeba_classes)\n",
    "sngan_wgan_gp_celeba = generators.GeneratorSNGANWGANGP_V2_0(input_dim = generator_input_dim4)\n",
    "\n",
    "model_path1 = '../implemented-gans-architectures/wgan-gp-sngan/mnist/saved-models/gen_conditional_wgan_gp_sngan_mnist.pth'\n",
    "model_path2 = '../implemented-gans-architectures/wgan-gp-sngan/fashion-mnist/saved-models/gen_conditional_wgan_gp_sngan_fashion_mnist.pth'\n",
    "model_path3 = '../implemented-gans-architectures/wgan-gp-sngan/emnist-letters/saved-models/gen_conditional_wgan_gp_sngan_emnist_letters.pth'\n",
    "model_path4 = '../implemented-gans-architectures/wgan-gp-sngan/celeba/saved-models/gen_conditional_wgan_gp_sngan_celeba.pth'\n",
    "\n",
    "sngan_wgan_gp_mnist.load_state_dict(torch.load(model_path1, map_location = torch.device(device)))\n",
    "sngan_wgan_gp_mnist.eval()\n",
    "sngan_wgan_gp_fashion_mnist.load_state_dict(torch.load(model_path2, map_location = torch.device(device)))\n",
    "sngan_wgan_gp_fashion_mnist.eval()\n",
    "sngan_wgan_gp_emnist_letters.load_state_dict(torch.load(model_path3, map_location = torch.device(device)))\n",
    "sngan_wgan_gp_emnist_letters.eval()\n",
    "sngan_wgan_gp_celeba.load_state_dict(torch.load(model_path4, map_location = torch.device(device)))\n",
    "sngan_wgan_gp_celeba.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_image(n_classes, conditional_class, model_generation, is_celeba = False):\n",
    "    '''\n",
    "    creates a synthetic image generated by GANs using conditioned classes.\n",
    "\n",
    "    Input:\n",
    "        n_classes (int) --> total number of classes that the model can generate.\n",
    "        conditional_class (int) --> conditioned class for synthetic image generation.\n",
    "        model_generation (pytorch model) --> Pytorch model of GAN to generate the synthetic image.\n",
    "    Returns:\n",
    "        fake_image (tensor) --> tensor of the synthetic image generated by GAN.\n",
    "    '''\n",
    "\n",
    "    noise = utils.get_noise(n_samples = 1, input_dim = z_dim, device = device)\n",
    "    noise_conditional = torch.cat(tensors = (noise.float(), \n",
    "                                            F.one_hot(torch.tensor([conditional_class]), n_classes).float()), \n",
    "                                            dim = 1)\n",
    "    fake = model_generation(noise_conditional)\n",
    "\n",
    "    if is_celeba: return fake.detach().cpu().view(-1, *color_shape)[0] #.permute(1, 2, 0)\n",
    "    else: return fake.detach().cpu().view(-1, *gray_shape)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_png(image_tensor, image_dir, is_celeba = False):\n",
    "    '''\n",
    "    saves an image tensor in png format.\n",
    "\n",
    "    Input:\n",
    "        image_tensor (array) --> image tensor\n",
    "        image_dir (str) --> string with directory and image name.png\n",
    "    Returns:\n",
    "    '''\n",
    "    if is_celeba:\n",
    "        image_array = np.array(image_tensor.permute(1, 2, 0))\n",
    "        image_array = np.clip(image_array, a_min = 0, a_max = 1)\n",
    "        fig=plt.figure()\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.array(image_array))\n",
    "        plt.savefig(image_dir, bbox_inches = 'tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        image = torchvision.transforms.ToPILImage()(image_tensor)\n",
    "        image.save(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_directory(directory, extract):\n",
    "    '''\n",
    "    analyzes the amount of images present in subdirectories.\n",
    "\n",
    "    Input:\n",
    "        directory (string) --> main directory to be parsed.\n",
    "        extract (string) --> data extract type.\n",
    "    '''\n",
    "\n",
    "    count, sum = 0, 0\n",
    "    for _, label in enumerate(os.listdir(directory)):\n",
    "        count = len(os.listdir(directory + label))\n",
    "        print(f'{extract} images in \"{label}\" directory: {count} images')\n",
    "        sum += count \n",
    "        count = 0\n",
    "\n",
    "    print(f'\\n== {extract} total images: {sum} images ==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_images_mnist_and_fashion_mnist(directory_ref, directory_dst, sub_dir, n_classes, model_generation, count):\n",
    "    '''\n",
    "    creates synthetic folders from GAN templates.\n",
    "\n",
    "    Input:\n",
    "        directory_ref (string) --> reference directory for counting the images.\n",
    "        directory_dst (string) --> main directory where images will be stored.\n",
    "        sub_dir (string) --> sub directories indexed in order with classes.\n",
    "        n_classes (int) --> total number of classes that the model can generate.\n",
    "        model_generation (pytorch model) --> Pytorch model of GAN to generate the synthetic image.\n",
    "    '''\n",
    "\n",
    "    #count = 0\n",
    "    for num in range(0, 10):\n",
    "        for _ in range(0, len(os.listdir(directory_ref + sub_dir[num] + '/'))):\n",
    "                fake_image = make_fake_image(n_classes, num, model_generation)\n",
    "                tensor_to_png(fake_image, directory_dst + sub_dir[num] + f'/{count}.png')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_images_emnist_letters(directory_ref, directory_dst, sub_dir, n_classes, model_generation):\n",
    "    '''\n",
    "    creates synthetic folders from GAN templates.\n",
    "\n",
    "    Input:\n",
    "        directory_ref (string) --> reference directory for counting the images.\n",
    "        directory_dst (string) --> main directory where images will be stored.\n",
    "        sub_dir (string) --> sub directories indexed in order with classes.\n",
    "        n_classes (int) --> total number of classes that the model can generate.\n",
    "        model_generation (pytorch model) --> Pytorch model of GAN to generate the synthetic image.\n",
    "    '''\n",
    "\n",
    "    count = 0\n",
    "    for num in range(1, 27):\n",
    "        for _ in range(0, len(os.listdir(directory_ref + sub_dir[num - 1] + '/'))):\n",
    "                fake_image = make_fake_image(n_classes, num, model_generation)\n",
    "                tensor_to_png(fake_image, directory_dst + sub_dir[num - 1] + f'/{count}.png')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_images_celeba(directory_ref, directory_dst, sub_dir, n_classes, model_generation):\n",
    "    '''\n",
    "    creates synthetic folders from GAN templates.\n",
    "\n",
    "    Input:\n",
    "        directory_ref (string) --> reference directory for counting the images.\n",
    "        directory_dst (string) --> main directory where images will be stored.\n",
    "        sub_dir (string) --> sub directories indexed in order with classes.\n",
    "        n_classes (int) --> total number of classes that the model can generate.\n",
    "        model_generation (pytorch model) --> Pytorch model of GAN to generate the synthetic image.\n",
    "    '''\n",
    "\n",
    "    count = 0\n",
    "    for num in range(1, 3):\n",
    "        for _ in range(0, len(os.listdir(directory_ref + sub_dir[num - 1] + '/'))):\n",
    "                fake_image = make_fake_image(n_classes, num, model_generation, is_celeba = True)\n",
    "                tensor_to_png(fake_image, directory_dst + sub_dir[num - 1] + f'/{count}.png',\n",
    "                              is_celeba = True)\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Artificial Images from Image Sets\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directories = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "make_fake_images_mnist_and_fashion_mnist('mnist-dataset/MNIST/original-data/train/', \n",
    "                                         'mnist-dataset/MNIST/artificial-augmentation/train/', \n",
    "                                         sub_directories, mnist_classes, sngan_wgan_gp_mnist)\n",
    "make_fake_images_mnist_and_fashion_mnist('mnist-dataset/MNIST/original-data/test/', \n",
    "                                         'mnist-dataset/MNIST/artificial-augmentation/test/', \n",
    "                                         sub_directories, mnist_classes, sngan_wgan_gp_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images in \"eight\" directory: 5851 images\n",
      "Train images in \"five\" directory: 5421 images\n",
      "Train images in \"four\" directory: 5842 images\n",
      "Train images in \"nine\" directory: 5949 images\n",
      "Train images in \"one\" directory: 6742 images\n",
      "Train images in \"seven\" directory: 6265 images\n",
      "Train images in \"six\" directory: 5918 images\n",
      "Train images in \"three\" directory: 6131 images\n",
      "Train images in \"two\" directory: 5958 images\n",
      "Train images in \"zero\" directory: 5923 images\n",
      "\n",
      "== Train total images: 60000 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('mnist-dataset/MNIST/artificial-augmentation/train/', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images in \"eight\" directory: 974 images\n",
      "Test images in \"five\" directory: 892 images\n",
      "Test images in \"four\" directory: 982 images\n",
      "Test images in \"nine\" directory: 1009 images\n",
      "Test images in \"one\" directory: 1135 images\n",
      "Test images in \"seven\" directory: 1028 images\n",
      "Test images in \"six\" directory: 958 images\n",
      "Test images in \"three\" directory: 1010 images\n",
      "Test images in \"two\" directory: 1032 images\n",
      "Test images in \"zero\" directory: 980 images\n",
      "\n",
      "== Test total images: 10000 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('mnist-dataset/MNIST/artificial-augmentation/test/', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directories = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', \n",
    "                   'bag', 'ankle-boot']\n",
    "make_fake_images_mnist_and_fashion_mnist('fashion-mnist-dataset/FashionMNIST/original-data/train/', \n",
    "                                         'fashion-mnist-dataset/FashionMNIST/artificial-augmentation/train/', \n",
    "                                         sub_directories, fashion_mnist_classes, sngan_wgan_gp_fashion_mnist)\n",
    "make_fake_images_mnist_and_fashion_mnist('fashion-mnist-dataset/FashionMNIST/original-data/test/', \n",
    "                                         'fashion-mnist-dataset/FashionMNIST/artificial-augmentation/test/', \n",
    "                                         sub_directories, fashion_mnist_classes, sngan_wgan_gp_fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images in \"ankle-boot\" directory: 6000 images\n",
      "Train images in \"bag\" directory: 6000 images\n",
      "Train images in \"coat\" directory: 6000 images\n",
      "Train images in \"dress\" directory: 6000 images\n",
      "Train images in \"pullover\" directory: 6000 images\n",
      "Train images in \"sandal\" directory: 6000 images\n",
      "Train images in \"shirt\" directory: 6000 images\n",
      "Train images in \"sneaker\" directory: 6000 images\n",
      "Train images in \"t-shirt\" directory: 6000 images\n",
      "Train images in \"trouser\" directory: 6000 images\n",
      "\n",
      "== Train total images: 60000 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('fashion-mnist-dataset/FashionMNIST/artificial-augmentation/train/', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images in \"ankle-boot\" directory: 1000 images\n",
      "Test images in \"bag\" directory: 1000 images\n",
      "Test images in \"coat\" directory: 1000 images\n",
      "Test images in \"dress\" directory: 1000 images\n",
      "Test images in \"pullover\" directory: 1000 images\n",
      "Test images in \"sandal\" directory: 1000 images\n",
      "Test images in \"shirt\" directory: 1000 images\n",
      "Test images in \"sneaker\" directory: 1000 images\n",
      "Test images in \"t-shirt\" directory: 1000 images\n",
      "Test images in \"trouser\" directory: 1000 images\n",
      "\n",
      "== Test total images: 10000 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('fashion-mnist-dataset/FashionMNIST/artificial-augmentation/test/', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directories = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "                   'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "make_fake_images_emnist_letters('emnist-letters-dataset/EMNIST/original-data/train/', \n",
    "                                'emnist-letters-dataset/EMNIST/artificial-augmentation/train/', \n",
    "                                 sub_directories, emnist_letters_classes, sngan_wgan_gp_emnist_letters)\n",
    "make_fake_images_emnist_letters('emnist-letters-dataset/EMNIST/original-data/test/', \n",
    "                                'emnist-letters-dataset/EMNIST/artificial-augmentation/test/', \n",
    "                                 sub_directories, emnist_letters_classes, sngan_wgan_gp_emnist_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images in \"a\" directory: 4800 images\n",
      "Train images in \"b\" directory: 4800 images\n",
      "Train images in \"c\" directory: 4800 images\n",
      "Train images in \"d\" directory: 4800 images\n",
      "Train images in \"e\" directory: 4800 images\n",
      "Train images in \"f\" directory: 4800 images\n",
      "Train images in \"g\" directory: 4800 images\n",
      "Train images in \"h\" directory: 4800 images\n",
      "Train images in \"i\" directory: 4800 images\n",
      "Train images in \"j\" directory: 4800 images\n",
      "Train images in \"k\" directory: 4800 images\n",
      "Train images in \"l\" directory: 4800 images\n",
      "Train images in \"m\" directory: 4800 images\n",
      "Train images in \"n\" directory: 4800 images\n",
      "Train images in \"o\" directory: 4800 images\n",
      "Train images in \"p\" directory: 4800 images\n",
      "Train images in \"q\" directory: 4800 images\n",
      "Train images in \"r\" directory: 4800 images\n",
      "Train images in \"s\" directory: 4800 images\n",
      "Train images in \"t\" directory: 4800 images\n",
      "Train images in \"u\" directory: 4800 images\n",
      "Train images in \"v\" directory: 4800 images\n",
      "Train images in \"w\" directory: 4800 images\n",
      "Train images in \"x\" directory: 4800 images\n",
      "Train images in \"y\" directory: 4800 images\n",
      "Train images in \"z\" directory: 4800 images\n",
      "\n",
      "== Train total images: 124800 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('emnist-letters-dataset/EMNIST/artificial-augmentation/train/', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images in \"a\" directory: 800 images\n",
      "Test images in \"b\" directory: 800 images\n",
      "Test images in \"c\" directory: 800 images\n",
      "Test images in \"d\" directory: 800 images\n",
      "Test images in \"e\" directory: 800 images\n",
      "Test images in \"f\" directory: 800 images\n",
      "Test images in \"g\" directory: 800 images\n",
      "Test images in \"h\" directory: 800 images\n",
      "Test images in \"i\" directory: 800 images\n",
      "Test images in \"j\" directory: 800 images\n",
      "Test images in \"k\" directory: 800 images\n",
      "Test images in \"l\" directory: 800 images\n",
      "Test images in \"m\" directory: 800 images\n",
      "Test images in \"n\" directory: 800 images\n",
      "Test images in \"o\" directory: 800 images\n",
      "Test images in \"p\" directory: 800 images\n",
      "Test images in \"q\" directory: 800 images\n",
      "Test images in \"r\" directory: 800 images\n",
      "Test images in \"s\" directory: 800 images\n",
      "Test images in \"t\" directory: 800 images\n",
      "Test images in \"u\" directory: 800 images\n",
      "Test images in \"v\" directory: 800 images\n",
      "Test images in \"w\" directory: 800 images\n",
      "Test images in \"x\" directory: 800 images\n",
      "Test images in \"y\" directory: 800 images\n",
      "Test images in \"z\" directory: 800 images\n",
      "\n",
      "== Test total images: 20800 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('emnist-letters-dataset/EMNIST/artificial-augmentation/test/', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directories = ['female', 'male']\n",
    "make_fake_images_celeba('celeba-dataset/celeba/original-data/train/', \n",
    "                        'celeba-dataset/celeba/artificial-augmentation/train/', \n",
    "                        sub_directories, celeba_classes, sngan_wgan_gp_celeba)\n",
    "make_fake_images_celeba('celeba-dataset/celeba/original-data/test/', \n",
    "                        'celeba-dataset/celeba/artificial-augmentation/test/', \n",
    "                        sub_directories, celeba_classes, sngan_wgan_gp_celeba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images in \"female\" directory: 105746 images\n",
      "Train images in \"male\" directory: 76593 images\n",
      "\n",
      "== Train total images: 182339 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('celeba-dataset/celeba/artificial-augmentation/train/', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images in \"female\" directory: 12419 images\n",
      "Test images in \"male\" directory: 7841 images\n",
      "\n",
      "== Test total images: 20260 images ==\n"
     ]
    }
   ],
   "source": [
    "analyze_directory('celeba-dataset/celeba/artificial-augmentation/test/', 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
